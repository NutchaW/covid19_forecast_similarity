---
title: "Forecasting Model Similarity (for inc hosp)"
author: "Johannes Bracher, Evan Ray, Nick Reich, Nutcha Wattanachit, Li Shandross"
date: "06/10/2021"
header-includes:
   - \usepackage{tabularx}
   - \usepackage{hyperref}
   - \usepackage{wrapfig}
   - \usepackage{float}
   - \usepackage{colortbl}
   - \usepackage{pdflscape}
   - \usepackage{tabu}
   - \usepackage{xcolor}
output:
  pdf_document:
        latex_engine: xelatex
---

```{r setup, include=FALSE}
library(tidyverse)
library(energy)
library(knitr)
library(data.table)
library(covidHubUtils)
#devtools::install_github("reichlab/covidHubUtils")
library(lubridate)
library(zoltr)
library(igraph)
library(gtools)
library(gridExtra)
knitr::opts_chunk$set(echo=FALSE,
                       comment = FALSE, message=FALSE, fig.show= 'hold',fig.pos="H",table.placement='H',
                       fig.align = 'center')
```


# COVID-19 Forecasting Model Similarity Analysis for 1-4 Week Ahead Incident Hospitalization 

## 5 locations with the highest number of COVID-19 hospitalizations by the end of February 2021

The pairwise approximated Cramer's distances are calculated for the models that have complete submissions for all target, all 5 locations with the highest number of COVID-19 hospitalizations by end of May 2021, all probability levels, from the target end date of December, 17th 2020 to June 10th, 2021 .

```{r}
source("./functions/distance_func_script.R")
# set targets for analysis
target_horizon <- 1:4
target_var <- "inc hosp"
# each target will have different sets of models based on the current filtering
## high count
wide_frame_hosp <- read.csv("./data/quantile_frame_hosp_top.csv")

# find models that don't forecast for a long enough date range
summary <- wide_frame_hosp %>% 
  filter(location == "6", quantile == 0.05, horizon_week == 1) %>%
  select(model, forecast_date, target_end_date, horizon_week) %>%
  group_by(model) %>%
  summarise(n())

little_models <- summary %>%
  filter(`n()` < 20, model != "UCLA-SuEIR") %>% 
  #UCLA-SuEIR doesn't have all locations and was already eliminated
  pull(model)


h_frame_high <- wide_frame_hosp %>% 
  frame_format2() %>% #must run code chunk below
  select(-little_models) # remove models that don't have enough forecasts


#############
library(ggplot2)
base_data <- filter(wide_frame_hosp, location == "6", quantile == 0.05, horizon_week == 1)
ggplot(base_data, aes(x = target_end_date, y = value, color = model)) + geom_point() + geom_line()

check <- hosp_forecasts_high %>% 
  filter(model == "UCLA-SuEIR") %>%
  select(model, forecast_date, target_end_date, location, horizon_week) %>%
  group_by(location) %>%
  summarise(n())
################


# d_frame <- frame_format(wide_frame_death) 
# c_frame <- frame_format(wide_frame_case) 
## low count
# wide_frame_death_low <- read.csv("./data/quantile_frame_bottom.csv") 
# wide_frame_case_low <- read.csv("./data/quantile_frame_inc_bottom.csv") 
# d_frame_low <- frame_format(wide_frame_death_low) 
# c_frame_low <- frame_format(wide_frame_case_low) 

```

```{r}
# rewrite frame_format() to work w/ hosp data
frame_format2 <- function(zoltr_frame){
  n_locs <- length(unique(zoltr_frame$location))
  # filter
  formatted_frame <- zoltr_frame %>%
    dplyr::filter(!any(is.na(value)),
                  !any(is.null(value))) %>%
    # filtering on quantile, which is the smallest
    dplyr::group_by(location, horizon_week, target_end_date, model) %>%
    mutate(n_q = n_distinct(quantile)) %>%
    ungroup() %>%
    dplyr::filter(n_q==max(n_q)) %>%
    dplyr::select(-"n_q") %>%
    # start filtering date and location and horizon
    group_by(model, horizon,  target_end_date) %>% #Add count of locations
    mutate(n_locations = n_distinct(location)) %>%
    dplyr::filter(n_locations==n_locs) %>%
    ungroup()  %>%
    group_by(model, location, target_end_date) %>% #Add count of weeks
    dplyr::mutate(n_horizons = n_distinct(horizon_week)) %>%
    dplyr::filter(n_horizons==max(n_horizons)) %>%
    ungroup() %>%
    group_by(model, horizon, location) %>%
    mutate(n_dates = n_distinct(target_end_date)) %>%
    dplyr::filter(n_dates==max(n_dates)) %>%
    ungroup() %>%
    dplyr::select(-c("n_horizons","n_locations","n_dates"))
  # final clean-up
  matrix_frame <- formatted_frame %>%
    dplyr::select("location","target_variable","target_end_date",
                  "type","quantile","model","value","horizon_week") %>%
    rename(horizon = `horizon_week`) %>% 
    dplyr::arrange(location,horizon,target_variable,target_end_date,model,quantile) %>%
    tidyr::pivot_wider(names_from = model, values_from = value) %>%
    dplyr::select_if(~ !any(is.na(.)))
  return(matrix_frame)
} 



  
```



```{r}
# hosp forecast
loc_name_high <-  unique(wide_frame_hosp[,c("abbreviation","location")])
# calculate distance matrices
q_set_high <- unique(h_frame_high$quantile) 
approx_cd_list_high <- build_distance_frame(h_frame_high, 
                           horizon_list=c(1:4),
                           target_list="inc hosp",
                           approx_rule="trapezoid_riemann",
                           tau_F=q_set_high,tau_G=q_set_high)

######## Scrapwork - trying to figure out why running the above code throws an error
    q_F_ordered <- sort(q_F)
    q_G_ordered <- sort(q_G)

tar_loc <- main_frame %>%
            dplyr::filter(location==unique(main_frame$location),
                          target_variable=="inc death",
                          horizon==c(1:4)) 
            end_dates <- unique(tar_loc$target_end_date)
          
 
single_matrix <- tar_loc %>%
              dplyr::filter(target_end_date==end_dates) %>%
              dplyr::arrange(quantile) %>%
              cd_combination(., "trapezoid_riemann", q_set,q_set) %>%
              dplyr::mutate(horizon=horiz,
                            location=loc,
                            target_variable=target,
                            target_end_date=end_date)
            rbind(dist_frame,single_matrix) -> dist_frame

            
             single_tarloc<- single_matrix[ , colSums(is.na(single_matrix)) == 0]    
    tmp <- single_tarloc %>%
    dplyr::select(-c("target_variable","target_end_date","location","horizon"))

    is.numeric(unlist(tmp[,eg[1,2]]))
    
  nc <- ncol(tmp)
  cnames <- colnames(tmp)
  eg <- expand.grid(1:nc, 1:nc)
  nr <- nrow(eg)
  v <- vector(length=nr)
  for (i in 1:nr) {
    cc <- calc_cramers_dist_one_model_pair(as.numeric(unlist(tmp[,eg[i,1]])),
                                           q_set_high,
                                           as.numeric(unlist(tmp[,eg[i,2]])),
                                           q_set_high,
                                           "trapezoid_riemann")
    v[i] <- cc
  } 
  
  q_F_ordered <- sort((unlist(tmp[,eg[i,1]])))
  tau_F_ordered <- sort(q_set_high)
  
  
#  calc_cramers_dist_unequal_space <-
 # function(q_F, tau_F, q_G, tau_G, approx_rule) {
  approx_rule = "trapezoid_riemann"
    # check quantile order
    q_F_ordered <- sort(as.numeric(unlist(tmp[,eg[1:9,1]])))
    q_G_ordered <- sort(as.numeric(unlist(tmp[,eg[1:9,2]])))
 
    # check probability level order
    tau_F_ordered <- sort(q_set_high)
    tau_G_ordered <- sort(q_set_high)

    N <- length(q_F_ordered)
    M <- length(q_G_ordered)
    # pool quantiles:
    q0 <- c(q_F_ordered, q_G_ordered)
    # indicator whether the entry is from F or G
    q <- q0[order(q0)]
    tf <- unlist(sapply(q, function(x) ifelse(x %in% q_F_ordered,tau_F_ordered[which(x == q_F_ordered)],0)))
    tg <- unlist(sapply(q, function(x) ifelse(x %in% q_G_ordered,tau_G_ordered[which(x == q_G_ordered)],0)))
    diffs_q <- diff(q)
    # probability level vectors
    tau_F_v <- cummax(tf)
    tau_G_v <- cummax(tg)
    if (approx_rule == "left_sided_riemann") {
      cvm <-
        sum(((tau_F_v[1:(N + M) - 1] - tau_G_v[1:(N + M) - 1]) ^ 2) * diffs_q)
    } else if (approx_rule == "trapezoid_riemann") {
      cvm <-
        sum((((tau_F_v[1:(N + M) - 1] - tau_G_v[1:(N + M) - 1]) ^ 2 + (tau_F_v[2:(N +
                                                                                       M)] - tau_G_v[2:(N + M)]) ^ 2
        ) / 2) * diffs_q)
    }
cvm


#explore build_distance_frame()----------------------------------------------------#
#(model_dataframe, horizon_list,target_list, approx_rule,tau_F,tau_G)
  main_frame <- d_frame %>% 
      dplyr::mutate(horizon = as.numeric(as.character(horizon)),
                    target_variable = as.character(target_variable),
                    location = as.character(location), 
                    target_end_date = as.Date(target_end_date)) %>%
      dplyr::filter(target_variable %in% "inc death",
                    horizon %in% c(1:4)) 
  if("forecast_date" %in% c(colnames(main_frame))){
    main_frame <- main_frame %>%
      dplyr::select(-"forecast_date")
  }
  ## apply distance_combination function 
  locations <- unique(main_frame$location)
  dist_frame <- data.frame()
  for(loc in locations){
      for(target in "inc hosp"){
        for(horiz in c(1:4)){
          tar_loc <- main_frame %>%
            dplyr::filter(location==loc,
                          target_variable==target,
                          horizon==horiz) 
          end_dates <- unique(tar_loc$target_end_date)
          for(end_date in end_dates){
            single_matrix <- tar_loc %>%
              dplyr::filter(target_end_date==end_date) %>%
              dplyr::arrange(quantile) %>%
              cd_combination(., "trapezoid_riemann", q_set_high,q_set_high) %>%
              dplyr::mutate(horizon=horiz,
                            location=loc,
                            target_variable=target,
                            target_end_date=end_date)
            rbind(dist_frame,single_matrix) -> dist_frame
          }
        }
      }
  }
#-----------------------------------------------------------------------------------#

  
```

```{r}

  
# extract data
total_frame <- approx_cd_list_high[[1]] %>%
  dplyr::mutate(pair=paste(model_1,model_2,sep=" vs "))
total_frame$target_end_date <- as.Date(total_frame$target_end_date,origin="1970-01-01")

# build some data frame
for(loc in loc_name$location){
  tmp <- approx_cd_list[[2]] %>% 
    dplyr::filter(location==loc) 
  tmp_list <-  lapply(1:4, function(x) cd_matrix(tmp,x))
  assign(paste0("d_frame_loc",loc), tmp_list)
}

# build heatmaps and scatter plots
for(loc in loc_name$location){
    tmp <- approx_cd_list[[2]] %>%
    dplyr::filter(location==loc)
    assign(paste0("p_",loc),
      distance_heatmap(tmp,
                       paste0(loc_name$abbreviation[which(loc_name$location==loc)],
                                "- Mean Approx. CD - Inc Death Forecasts by Horizon")))
      tmp <-total_frame %>%
          dplyr::filter(location==loc) %>%
          dplyr::group_by(horizon,target_end_date) %>%
          dplyr::filter(model_1 =="COVIDhub-ensemble",
                        model_2 != "COVIDhub-ensemble") %>%
          dplyr:: ungroup()
      assign(paste0("t_",loc),
             scatter(tmp,
            paste0("Approx. CD from COVIDhub-ensemble Over Time  - ",
                loc_name$abbreviation[which(loc_name$location==loc)]) )
    )
}
```


We can visualize the mean approximated pairwise distances across all time points in a heat map shown below. The distance from the model to itself is zero. The $x-$axis is arranged based in an ascending order of the model's approximate pairwise distance from the COVIDhub-ensemble. So, the first model is the model that is most dissimilar (on average) to the ensemble in this time frame.

```{r,fig.align='center'}
# print heatmapes
for(loc in loc_name$location){
  print(do.call(get,list(paste0("p_",loc))))
}
```

We can also look at the approximated pairwise distances to see how the models become more similar or dissimilar over time.

```{r,fig.align='center'}
# print scatterplots
for(loc in loc_name$location){
  print(do.call(get,list(paste0("t_",loc))))
}
```

We can cluster the distances using hierarchical clustering. Different linkages will result in different clusters, we probably should investigate more later. 

```{r}
library(ggdendro)
for(j in 1:5){
for(i in 1:4){
    assign(paste0("dp_",i),
    ggdendrogram(
      hclust(as.dist(get(paste0("d_frame_loc",loc_name$location[j]))[[i]]), method = "ward.D", members = NULL)
      ,size = 2) +
      labs(title=paste0("Dendrogram - ",i, " wk ahead inc death - ",loc_name$abbreviation[j]))+
      xlab("") +
      ylab("Mean Cramer's Distance") +
      theme(axis.text.x = element_text(size=5),
            axis.text.y = element_text(size=7),
            plot.margin=unit(c(0,0,0,0),"cm"),
            plot.title = element_text(size=8)))
  } 
  grid.arrange(dp_1,dp_2,dp_3,dp_4,nrow=2)
}
```

## 5 locations with the lowest number of COVID-19 deaths by the end of February 2021

The pairwise approximated Cramer's distances are calculated for the models that have complete submissions for all target, all 5 locations with the lowest number of COVID-19 deaths by the end of February 2021, all probability levels, from the target end date of October, 17th 2020 to May 29th, 2021 .

```{r}
# death forecast
loc_name <-  unique(wide_frame_death_low[,c("abbreviation","location")])
# calculate distance matrices
q_set <- unique(d_frame_low$quantile) 
approx_cd_list <- build_distance_frame(d_frame_low, 
                           horizon_list=c(1:4),
                           target_list="inc death",
                           approx_rule="trapezoid_riemann",
                           tau_F=q_set,tau_G=q_set)

# extract data
total_frame <- approx_cd_list[[1]] %>%
  dplyr::mutate(pair=paste(model_1,model_2,sep=" vs "))
total_frame$target_end_date <- as.Date(total_frame$target_end_date,origin="1970-01-01")

# build some data frame
for(loc in loc_name$location){
  tmp <- approx_cd_list[[2]] %>% 
    dplyr::filter(location==loc) 
  tmp_list <-  lapply(1:4, function(x) cd_matrix(tmp,x))
  assign(paste0("d_frame_loc",loc), tmp_list)
}

# build heatmaps and scatter plots
for(loc in loc_name$location){
    tmp <- approx_cd_list[[2]] %>%
    dplyr::filter(location==loc)
    assign(paste0("p_",loc),
      distance_heatmap(tmp,
                       paste0(loc_name$abbreviation[which(loc_name$location==loc)],
                                "- Mean Approx. CD - Inc Death Forecasts by Horizon")))
      tmp <-total_frame %>%
          dplyr::filter(location==loc) %>%
          dplyr::group_by(horizon,target_end_date) %>%
          dplyr::filter(model_1 =="COVIDhub-ensemble",
                        model_2 != "COVIDhub-ensemble") %>%
          dplyr:: ungroup()
      assign(paste0("t_",loc),
             scatter(tmp,
            paste0("Approx. CD from COVIDhub-ensemble Over Time  - ",
                loc_name$abbreviation[which(loc_name$location==loc)]) )
    )
}
```

We can visualize the mean approximated pairwise distances across all time points in a heat map shown below. The distance from the model to itself is zero. The $x-$axis is arranged based in an ascending order of the model's approximate pairwise distance from the COVIDhub-ensemble. So, the first model is the model that is most dissimilar (on average) to the ensemble in this time frame.

```{r,fig.align='center'}
# print heatmapes
for(loc in loc_name$location){
  print(do.call(get,list(paste0("p_",loc))))
}
```

We can also look at the approximated pairwise distances to see how the models become more similar or dissimilar over time.

```{r,fig.align='center'}
# print scatterplots
for(loc in loc_name$location){
  print(do.call(get,list(paste0("t_",loc))))
}
```

We can cluster the distances using hierarchical clustering. Different linkages will result in different clusters, we probably should investigate more later. 

```{r}
library(ggdendro)
for(j in 1:5){
for(i in 1:4){
    assign(paste0("dp_",i),
    ggdendrogram(
      hclust(as.dist(get(paste0("d_frame_loc",loc_name$location[j]))[[i]]), method = "ward.D", members = NULL)
      ,size = 2) +
      labs(title=paste0("Dendrogram - ",i, " wk ahead inc death - ",loc_name$abbreviation[j]))+
      xlab("") +
      ylab("Mean Cramer's Distance") +
      theme(axis.text.x = element_text(size=5),
            axis.text.y = element_text(size=7),
            plot.margin=unit(c(0,0,0,0),"cm"),
            plot.title = element_text(size=8)))
  } 
  grid.arrange(dp_1,dp_2,dp_3,dp_4,nrow=2)
}
```